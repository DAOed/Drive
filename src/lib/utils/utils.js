
import { coreFolders } from "@constants"
import { loadFolderMetas, createFolderMetas } from "@lib/utils"
import md5 from "md5"

import store from "@store"

export const makePath = (parentPath, name) => {
  return parentPath + "/" + name.replace(/\W+/g, "-").toLowerCase()
}

export const formatBytes = (bytes = 0, decimals = 2) => {
  if (bytes === 0) return "0 Bytes"

  const k = 1024
  const dm = decimals < 0 ? 0 : decimals
  const sizes = ["Bytes", "KB", "MB", "GB", "TB", "PB", "EB", "ZB", "YB"]

  const i = Math.floor(Math.log(bytes) / Math.log(k))

  return parseFloat((bytes / Math.pow(k, i)).toFixed(dm)) + " " + sizes[i]
}

export const loadFolderStats = async () => {
  let baseFolderNames = Object.values(coreFolders)
  let existingFolders = await loadFolderMetas(baseFolderNames)
  let coreFolderStats = {}

  Object.keys(coreFolders).map((f) => {
    let targetFolder = existingFolders.find((ef) => ef.name === f.toUpperCase()) || {}

    coreFolderStats[f] = {
      name: (targetFolder.name || f).toLowerCase(),
      files: targetFolder.files ? targetFolder.files.length : 0,
      size: targetFolder.size || 0,
      subfolders: targetFolder.subfolders ? targetFolder.subfolders.length : 0,
      featuredFolders: ((f === "files") && targetFolder.subfolders) ? targetFolder.subfolders.filter((f) => f.starred).slice(0, 5) : []
    }
  })

  store.dispatch("coreFolderStats", coreFolderStats)
}

export const readyCoreFolders = async (returnFolderName) => {
  let baseFolderNames = Object.values(coreFolders)

  let returnFolderIndex = baseFolderNames.findIndex((name) => name === returnFolderName)
  let returnFolderMeta = null

  // get metas of all existing folders
  let rawExistingFolders = await loadFolderMetas(baseFolderNames)
  let validExistingFolders = rawExistingFolders.filter(Boolean)
  // index might be 0, if you use `if (returnFolderIndex) ...` it returns because of value is `0`, even though its an index
  returnFolderMeta = rawExistingFolders[returnFolderIndex]

  // prepare core folders' stats and set to store
  let coreFolderStats = {}

  Object.keys(coreFolders).map((f) => {
    let targetFolder = validExistingFolders.find((ef) => ef.name === f.toUpperCase()) || {}

    coreFolderStats[f] = {
      name: (targetFolder.name || f).toLowerCase(),
      files: targetFolder.files ? targetFolder.files.length : 0,
      size: targetFolder.size || 0,
      subfolders: targetFolder.subfolders ? targetFolder.subfolders.length : 0,
      featuredFolders: ((f === "files") && targetFolder.subfolders) ? targetFolder.subfolders.filter((f) => f.starred).slice(0, 5) : []
    }
  })
  store.dispatch("coreFolderStats", coreFolderStats)

  // filter out folders that do not have the metas

  let missingFolders = rawExistingFolders.map((f, i) => {
    if (!f) {
      return baseFolderNames[i]
    }
  })

  missingFolders = missingFolders.filter(Boolean)

  let missingFoldersMetas = missingFolders.map((folder) => ({
    name: folder,
    tag: folder,
    private: true,
    path: folder,
    id: folder,
    sys: true,
    level: 0
  })
  )

  // create missing folders
  await createFolderMetas(null, null, missingFoldersMetas)

  return returnFolderMeta
}

export const readLocalFiles = async (files) => {
  let fileData = []

  for (let i = 0; i < files.length; i++) {
    const file = files[i]
    let content = await readLocalFile(file)

    let data = {
      name: file.name,
      private: true,
      size: file.size,
      id: md5(content),
      content
      // path: '' // will be generated by the creation function
    }

    fileData.push(data)
  }
  return fileData
}

export const readLocalFile = (file, mode) => {
  return new Promise((resolve, reject) => {
    let reader = new FileReader()

    reader.onload = () => {
      resolve(reader.result)
    }

    reader.onerror = reject

    switch (mode) {
    case "readAsBinaryString":
      reader.readAsBinaryString(file)
      break
    case "readAsArrayBuffer":
      reader.readAsArrayBuffer(file)
      break
    default:
      reader.readAsDataURL(file)
    }
  })
}

export const readExternalFile = (file, mode) => {
  return new Promise(async (resolve, reject) => {
    fetch(file.url)
      .then(res => res.blob())
      .then(blob => {
        let reader = new FileReader()

        reader.onload = () => {
          let result = reader.result

          let data = {
            name: file.name || file.url.split("/").pop(),
            private: true,
            size: result.length,
            id: md5(result),
            content: result
            // path: '' // will be generated by the creation function
          }
          resolve(data)
        }

        reader.onerror = reject

        switch (mode) {
        case "readAsBinaryString":
          reader.readAsBinaryString(blob)
          break
        case "readAsArrayBuffer":
          reader.readAsArrayBuffer(blob)
          break
        default:
          reader.readAsDataURL(blob)
        }
      })
  })
}

export const uniquifyNames = (arr) => {
  var count = {}
  arr.forEach(function (x, i) {
    if (arr.indexOf(x) !== i) {
      var c = x in count ? count[x] = count[x] + 1 : count[x] = 1
      var j = c + 1
      var k = fileName(x) + "(" + j + ")." + fileExt(x)

      while (arr.indexOf(k) !== -1) k = fileName(x) + "(" + (++j) + ")." + fileExt(x)
      arr[i] = k
    }
  })
  return arr
}

export const fileName = (name) => {
  let parts = name.split(".")
  return parts.slice(0, parts.length - 1).join(".")
}

export const fileExt = (name) => name.split(".").pop()

export const uniquifyNewFileNames = (oldFiles, newFiles) => {
// get names
  let oldNames = oldFiles.map(({ name }) => name)
  let newNames = newFiles.map(({ name }) => name)

  // check for duplicates in new items
  let allNames = [...oldNames, ...newNames]

  // make names unique
  let uniqueNames = uniquifyNames(allNames)
  let newUniqueNames = uniqueNames.slice(oldFiles.length)

  return newUniqueNames.map((nom, index) => {
    return {
      ...newFiles[index],
      name: newUniqueNames[index]
    }
  })
}
